\documentclass[12pt]{IEEEtran}


\title{
Age Detection \\

\large Laurea Magistrale in Scienze e Ingegneria Informatica AA2019/2020\\
\large Teorie e Tecniche del Riconoscimento}
\author{Giovanni Bagolin - VR445681\\Andrei Tsoi -VR446397}

\usepackage{adjustbox}
\usepackage{graphicx}
\usepackage[italian]{babel}

\begin{document}
\maketitle

\begin {abstract}
Il progetto di Age Detection si occupa di stimare l'età di un individuo attribuendola ad una fascia ben definita.\\
Il progetto è sviluppato su più livelli dove ognuno dei quali si occupa di fasce d'eta differenti:
\begin{itemize}
\item  Binary Age Detection: il classificatore permette di distinguere solamente due fasce d'età, utilizzato per verificare se un individuo può essere categorizzato come giovane o come anziano.
\item Ternary Age Detection: il classificatore permette di distinguere tre fasce d'età, rispettivamente giovane, adulto e anziano.
\item Multiclass Age Detection: il classificatore permette di distinguere molteplici fasce d'età che vanno da decade in decade, tuttavia questo tipo di classificatore non è stato implementato correttamente in quanto necessita di analisi biometriche avanzate.
\end{itemize}
\end{abstract}

\section{Motivation  and Rationale}
L'age detection degli individui è utile in molteplici campi che vanno dall'analisi demografica della popolazione alla distinzione di interessi di varie fasce d'eta nelle loro abitudini quotidiane.\\
L'analisi demografica della popolazione permette di stimare l'età media di uno stato, regione o città. Grazie all'analisi demografica si ottengono informazioni sulla struttura di una popolazione: suddividendo la popolazione in fasce d'eta, in base alle proporzioni tra queste fasce la struttura della popolazione può essere descritta come progressiva (maggioranza di popolazione giovane),  regressiva(maggioranza di popolazione anziana) o stazionaria (equivalenza tra popolazioni giovane e anziane).\\
Un'altro campo in cui  l'age detection può essere utile è stimare le abitudini degli individui di un gruppo sociale. L'affluenza di una certa categoria di persone in dato luogo (come un negozio, centro commerciale) o evento(come feste, raduni, fiere) può descrivere gli interessi di ogni fascia d'età. Questa analisi può successivamente tornare utile per fini economici e sociali come per esempio pubblicità mirate, organizzazione di eventi in determinati modi per attrarre determinate fasce d'età, vendita di oggetti mirati a fasce d'età (videogiochi, accessori auto, sedie a rotelle, bare).  

\section{Objectives}
Gli obiettivi si concentrano nella progettazione e modellazione di uno strumento che possa distinguere individui sulla base della loro età. Andando nel dettaglio gli obiettivi di un Binary Age Detection si concentrano nell'individuazione e separazione delle feature che possano aiutare a discriminare un giovane da un anziano, tale obiettivo è il più semplice da raggiungere ed anche il più preciso nell'esecuzione del discriminatore(come si vedrà nelle sezioni successive) in quanto le features sono meglio separabili.\\
Più complicato è il raggiungimento degli obiettivi di un Ternary Age Detection: a differenza del classificatore binario, in quello ternario si devono individuare features che possano distinguere tre tipologie di persone (giovani, adulte ed anziane), pertanto molte features possono essere in comune, rendendo più complicata e meno efficiente la discriminazione tra fasce d'età.\\
Il Multiclass Age Detection risulta essere in assoluto il più complicato da realizzare: gli obiettivi di un classificatore di questo tipo sono quelli di distinguere fasce d'eta vicine tra loro (ad esempio distinguere un trentenne da un quarantenne). Tale obiettivi sono difficili da ottenere in quanto le feature discriminatorie sono sempre meno cosi come la dimensione del dataset utilizzato per il training. \\ 

\section{Methodology}
\subsection{Dataset}
Il dataset è strutturato in sette classi, dove ogni classe rappresenta una fascia d'età contenente 974 immagini: 
\begin{itemize}
    \item Classe 0: Rappresenta i bambini dai 2 ai 9 anni. 
    \item Classe 1: Rappresenta i ragazzi dai 10 ai 19 anni. 
    \item Classe 2: Rappresenta gli adulti dai 20 ai 29 anni.
    \item Classe 3: Rappresenta gli adulti dai 30 ai 39 anni. 
    \item Classe 4: Rappresenta gli adulti dai 40 ai 49 anni.
    \item Classe 5: Rappresenta gli adulti dai 50 ai 59 anni.
    \item Classe 6: Rappresenta gli anziani dai 60 in poi. \\
\end{itemize} 
Per avere la massima rappresentatività di ogni dato, attraverso un algoritmo di face-detection, si è estratta la faccia, di conseguenza si è ridotto al minimo il rumore (come lo sfondo e le altre componenti del corpo) che avrebbe influenzato in negativo la classificazione. Ogni dato appartenente al dataset rappresenta esclusivamente una faccia. \\
Per il Binary Age Detection, si è scelto di utilizzare la classe 6 per gli anziani in confronto ad una qualsiasi delle altre classi.\\
Nel caso del classificatore ternario, le classi utilizzate sono: la classe 0 per rappresentare i giovani, la classe 3 per gli adulti, e la classe 6 per gli anziani. 
Tali classi sono state scelte in quanto riescono a distanziarsi il più possibile in termini di features, l'una dall'altra, potendo aver quindi una classificazione più precisa e di conseguenza migliore. \\
Il Multiclass Age Detection è stato implementato in due versioni. Nella prima versione sono state utilizzate quattro classi partizionate in modo opportuno: 
\begin{itemize}
    \item Classe 0: la classe rimane invariata. 
    \item Classe 1: è composta dalla metà più vecchia della classe 2 più la metà più giovane della classe 3. 
    \item Classe 2: contiene la metà più vecchia della classe 4 più la metà più giovane della classe 5. 
    \item Classe 3: la classe rimane invariata. \\ 
\end{itemize}
\newpage
La seconda versione utilizza tutte le classi del dataset, nella quale si otterrebbe un Age Detection ideale, ovvero che possa rilevare il più basso range d'età al quale una persona può appartenere. Tuttavia, i risultati ottenuti con quest'ultimo, non rispecchiano questa idea. 
\subsection{Suddivisione Dataset in Training Set e Testing Set}
Un classificatore necessita di una fase di addestramento, la quale deve essere fatta su di un'ampia quantità di dati, il training set. Avendo quindi una quantità limitata di dati, occorre partizionare il dataset in maniera opportuna. Tale partizionamento è rappresentato dal 90\% del dataset come training set, e il restante 10\% come testing. Questi valori si possono modificare dando maggiore priorità al testing, ma penalizzando la fase di training, e quindi penalizzando l'accuratezza totale del classificatore. 
\subsection{Analisi e Ridimensionalità delle Features}
I vari classificatori utilizzano varie versioni del dataset, con opportune ridimensionalità delle features. \\
Tali ridimensionalità sono necessarie per incrementare le performance dei classificatori. 
Le tecniche di ridimensionalità utilizzate sono: 
\begin{itemize}
    \item Nessuna ridimensionalità: al classificatore viene passato il dataset, dove ogni dato ha una dimensionalità di 40.000 features (il dato è un'immagine 200x200 in scala di grigi).
    \item Principal Components Analysis: il dataset viene ridimensionato sulla base delle sue componenti principali, la quantità di tali componenti viene arbitrariamente assegnata. Si fa notare che vi è un cambiamento in termini di ordini di grandezze rispetto alla dimensionalità originale. 
    \item Features Extractor: il dataset viene ridimensionato utilizzando l'estrattore delle features fornito in laboratorio. Tale estrattore si basa su una rete neurale, quindi l'estrazione risulterà essere lenta, ottenendo un guadagno prestazionale solamente durante la fase di addestramento e di classificazione. Questo estrattore, restituisce 2048 features per ogni immagine. \\
\end{itemize}

\subsection{Tecniche di classificazione}
Per il problema di classificazione binaria, inizialmente, si è pensato di utilizzare un classificatore di Bayes, ma le features che rappresentano giovani e anziani non sono risultate linearmente separabili anche riducendo la dimensionalità delle features. Pertanto, l'approccio al problema è stato cambiato, provando altri classificatori come Support Vector Machine e K-Nearest-Neighbor. \\
Il classificatore Support Vector Machine risulta essere ideale per questa tipologia di problemi, in quanto è in grado di separare le features (anche non linearmente separabili), mappandole in altri spazi attraverso opportuni kernel. In aggiunta vengono utilizzate  delle variabili slack, che insieme ad un parametro di costo C, consentono di oltrepassare l'iperpiano di separazione andando ad esplorare ulteriori features eventualmente, migliorando la classificazione. \\
Un altro classificatore utilizzato è il K-Nearest-Neighbor, tuttavia, risulta essere meno preciso rispetto al Support Vector Machine. \\
Tale carenza di precisione è derivata dal fatto che il K-Nearest-Neighbor non mappa le features in altri spazi, ma per ogni feature appartenente ai dati di test ne analizza solamente l'intorno (composto da K features di addestramento vicine alla feature di test analizzata).Il risultato dell'analisi permette di classificare la feature, in base alla classe che si presenta più frequentemente nell'intorno. 


\section{Experiments and Results}
\subsection{Binary Age Detection - SVM}
Per quanto riguarda l'utilizzo del classificatore SVM, sono state realizzate tre versioni, rispettivamente: 
\begin{itemize}
    \item Classificatore con dati senza nessuna ridimensionalità. 
    \begin{table}[h]
    \caption {Accuratezza, Recall e Precisione al variare del numero di iterazioni} \label{tab:title} 
       \begin{adjustbox}{width=\columnwidth}
        \begin{tabular}{|c|c|c|c|c|}
        \hline
        \# Iterazioni      & 1 & 10 & 100 & 1.000 \\ \hline
        Accuratezza        &65.13\% &63.08\% &78.97\%  &89.74\%       \\ \hline
        Recall Classe 0    &80\%    &78\%    &66\%     &89\%       \\ \hline
        Recall Classe 6    &51\%    &48\%    &92\%     &91\%       \\ \hline
        Precision Classe 0 &62\%    &60\%    &89\%     &91\%       \\ \hline
        Precision Classe 6 &71\%    &68\%    &73\%     &89\%       \\ \hline
        \end{tabular}
        \end{adjustbox}
        \end{table} \newpage
        \begin{table}[h!]
        \caption {Accuratezza al variare del kernel addottato}
        \begin{adjustbox}{width=\columnwidth}
        \begin{tabular}{|c|c|c|c|c|}
        \hline
        Kernel      & Linear  & Poly    & RBF     & Sigmoid \\ \hline
        Accuratezza & 93.85\% & 94.36\% & 89.74\% & 49.74\% \\ \hline
        \end{tabular}
        \end{adjustbox}
        \end{table}
        \item Classificatore con dati ridimensionati con PCA. 
        \begin{table}[h]
    \caption {Accuratezza, Recall e Precisione al variare del numero di iterazioni} \label{tab:title} 
       \begin{adjustbox}{width=\columnwidth}
        \begin{tabular}{|c|c|c|c|c|}
        \hline
        \# Iterazioni      & 1 & 10 & 100 & 1.000 \\ \hline
        Accuratezza        &62.05\% &59.49\% &83.08\%  &92.31\%       \\ \hline
        Recall Classe 0    &79\%    &76\%    &71\%     &89\%       \\ \hline
        Recall Classe 6    &45\%    &43\%    &95\%     &91\%       \\ \hline
        Precision Classe 0 &59\%    &57\%    &93\%     &91\%       \\ \hline
        Precision Classe 6 &68\%    &64\%    &77\%     &89\%       \\ \hline
        \end{tabular}
        \end{adjustbox}
        \end{table} 
        \begin{table}[h!]
        \caption {Accuratezza al variare del kernel addottato}
        \begin{adjustbox}{width=\columnwidth}
        \begin{tabular}{|c|c|c|c|c|}
        \hline
        Kernel      & Linear  & Poly    & RBF     & Sigmoid \\ \hline
        Accuratezza & 93.85\% & 85.13\% & 92.31\% & 69.74\% \\ \hline
        \end{tabular}
        \end{adjustbox}
        \end{table}
        \item Classificatore ridimensionato con Feature Extractor con rete neurale. 
        \begin{table}[h]
    \caption {Accuratezza, Recall e Precisione al variare del numero di iterazioni} \label{tab:title} 
       \begin{adjustbox}{width=\columnwidth}
        \begin{tabular}{|c|c|c|c|c|}
        \hline
        \# Iterazioni      & 1 & 10 & 100 & 1.000 \\ \hline
        Accuratezza        &58.97\% &72.82\% &81.03\%  &89.23\%       \\ \hline
        Recall Classe 0    &72\%    &59\%    &68\%     &84\%       \\ \hline
        Recall Classe 6    &45\%    &87\%    &94\%     &95\%       \\ \hline
        Precision Classe 0 &57\%    &82\%    &92\%     &94\%       \\ \hline
        Precision Classe 6 &62\%    &68\%    &75\%     &85\%       \\ \hline
        \end{tabular}
        \end{adjustbox}
        \end{table} 
        \begin{table}[h!]
        \caption {Accuratezza al variare del kernel addottato}
        \begin{adjustbox}{width=\columnwidth}
        \begin{tabular}{|c|c|c|c|c|}
        \hline
        Kernel      & Linear  & Poly    & RBF     & Sigmoid \\ \hline
        Accuratezza & 89.23\% & 88.72\% & 89.23\% & 49.74\% \\ \hline
        \end{tabular}
        \end{adjustbox}
        \end{table}
        
    \end{itemize}
\newpage
\subsection{Binary Age Detection - KNN}
Per quanto riguarda l'utilizzo del classificatore KNN, sono state realizzate tre versioni, rispettivamente: \\
\begin{itemize}
    \item Classificatore con dati senza nessuna ridimensionalità. 
        \begin{table}[h!]
        \caption {Accuratezza al variare del numero di vicini}
        \begin{adjustbox}{width=\columnwidth}
        \begin{tabular}{|c|c|c|c|c|c|c|}
        \hline
        \# Vicini      &1  &3    &7  &10    &70  &100\\ \hline
        Accuratezza & 71\% &72.30\% & 75.89\% &75.89\% & 73\% & 67.69\%  \\ \hline
        \end{tabular}
        \end{adjustbox}
        \end{table}
        \item Classificatore con dati ridimensionati con PCA. 
        \begin{table}[h!]
        \caption {Accuratezza al variare del numero di vicini}
        \begin{adjustbox}{width=\columnwidth}
        \begin{tabular}{|c|c|c|c|c|}
        \hline
        \# Vicini      &3  & 7    & 10     & 70 \\ \hline
        Accuratezza & 93.85\% & 94.36\% & 89.74\% & 49.74\% \\ \hline
        \end{tabular}
        \end{adjustbox}
        \end{table}
        \item Classificatore ridimensionato con Feature Extractor con rete neurale. 
        \begin{table}[h!]
        \caption {Accuratezza al variare del numero di vicini}
        \begin{adjustbox}{width=\columnwidth}
        \begin{tabular}{|c|c|c|c|c|}
        \hline
        \# Vicini      &3  & 7    & 10     & 70 \\ \hline
        Accuratezza & 93.85\% & 94.36\% & 89.74\% & 49.74\% \\ \hline
        \end{tabular}
        \end{adjustbox}
        \end{table}
    \end{itemize}
    
\section{Conclusions}
Le conclusioni dovrebbero riassumere in poche righe  tutto ci\`o che \`e stato fatto. Un paio di righe descrivono i risultati osservati, in modo da introdurre poi la conclusione ``vera e propria''. Nel caso del corso, la ``lezione da portare a casa'' sar\`a quello che si \`e imparato svolgendo l'elaborato.



\bibliography{biblio}

\appendix
Se non avete abbastanza spazio, potete inserire le figure delle EFSM in una  pagina extra, appendice. Un esempio di come potete fare solo le Figure~\ref{fig:grande}, \ref{fig:piccola1}, \ref{fig:piccola2}.


\end{document}